{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Feature Engineering - Version 2.0\n",
    "\n",
    "## Objective\n",
    "Engineer 81 high-quality, interpretable features from raw game logs and shot chart data.\n",
    "\n",
    "## Features (81 total) - WITH DATA QUALITY FIXES\n",
    "\n",
    "1. **Rolling Averages (27)**: PTS, REB, AST, MIN, FGA, FTA, TOV, FG%, FG3%, FT%\n",
    "2. **Game Context (10)**: IS_HOME, REST_DAYS + quality fixes, SEASON timing\n",
    "3. **Player Role (5)**: RECENT_MIN_AVG, role categories (Bench/Rotation/Starter/Star)\n",
    "4. **Season Progression (5)**: Non-linear time effects (quadratic + phases)\n",
    "5. **Trends (7)**: PTS/REB/AST/MIN_TREND, PTS/REB/AST_VOLATILITY\n",
    "6. **Season Stats (9)**: Season averages + HOT_HAND momentum scores\n",
    "7. **Shot Location (20)**: Distribution, efficiency, quality by zone\n",
    "\n",
    "## Data Quality Improvements from v1.0:\n",
    "- âœ… **REST_DAYS capped at 7** (removes injury return contamination)\n",
    "- âœ… **Player role features** (model knows bench vs starter volatility)\n",
    "- âœ… **Fixed HOT_HAND** (now measures true momentum, not player quality)\n",
    "- âœ… **Quadratic season progression** (captures mid-season peak)\n",
    "- âœ… **Quality flags** (INCLUDE_IN_TRAINING for filtering outliers)\n",
    "\n",
    "## Output\n",
    "`data/processed/features_complete.parquet` - ~85,000 games Ã— 95 columns (81 features + metadata)\n",
    "\n",
    "**CRITICAL**: All features use `.shift(1)` to prevent data leakage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"âœ… Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 90,274 games from 369 players\n",
      "Date range: 2019-10-22 to 2024-04-14\n"
     ]
    }
   ],
   "source": [
    "# Load game logs\n",
    "df = pd.read_parquet('../data/raw/gamelogs_combined.parquet')\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "df = df.sort_values(['Player_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df):,} games from {df['Player_ID'].nunique()} players\")\n",
    "print(f\"Date range: {df['GAME_DATE'].min().date()} to {df['GAME_DATE'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rolling Averages (27 features)\n",
    "\n",
    "Core predictive features: recent performance trends for all major stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rolling averages (leakage-safe with .shift(1))...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Basic stats: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 193.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 27 rolling features created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating rolling averages (leakage-safe with .shift(1))...\\n\")\n",
    "\n",
    "# Basic stats: 3, 5, 10-game windows\n",
    "for stat in tqdm(['PTS', 'REB', 'AST', 'MIN', 'FGA', 'FTA', 'TOV'], desc=\"Basic stats\"):\n",
    "    for window in [3, 5, 10]:\n",
    "        df[f'{stat}_last_{window}'] = (\n",
    "            df.groupby('Player_ID')[stat]\n",
    "            .shift(1)\n",
    "            .rolling(window, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "# Shooting percentages: 5, 10-game windows\n",
    "for window in [5, 10]:\n",
    "    for pct in ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "        df[f'{pct}_last_{window}'] = (\n",
    "            df.groupby('Player_ID')[pct]\n",
    "            .shift(1)\n",
    "            .rolling(window, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "print(\"âœ… 27 rolling features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Game Context (10 features)\n",
    "\n",
    "**Data Quality Fixes Applied:**\n",
    "- REST_DAYS_CAPPED: Removes injury return contamination (cap at 7 days)\n",
    "- IS_SEASON_OPENER: Flag first 3 games per player-season\n",
    "- AVG_REST_LAST_5: Game load indicator\n",
    "- DAYS_NORM + DAYS_NORM_SQ: Captures non-linear season progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating game context features...\n",
      "\n",
      "âœ… 10 game context features created\n",
      "   REST_DAYS range: 1 - 717 days\n",
      "   REST_DAYS_CAPPED: 1 - 7 days\n",
      "   Season openers: 4,644 games (5.1%)\n",
      "   DAYS_INTO_SEASON: 17 to 318 days\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating game context features...\\n\")\n",
    "\n",
    "# Home/away indicator\n",
    "df['IS_HOME'] = df['MATCHUP'].apply(lambda x: 1 if 'vs.' in x else 0)\n",
    "\n",
    "# Rest days (original + capped)\n",
    "df['REST_DAYS'] = df.groupby('Player_ID')['GAME_DATE'].diff().dt.days.fillna(7)\n",
    "df['REST_DAYS_CAPPED'] = df['REST_DAYS'].clip(upper=7)  # FIX: Cap at 7\n",
    "\n",
    "# Back-to-back indicator\n",
    "df['BACK_TO_BACK'] = (df['REST_DAYS'] <= 1).astype(int)\n",
    "\n",
    "# Season opener flag (first 3 games per player-season)\n",
    "df['IS_SEASON_OPENER'] = (\n",
    "    df.groupby(['Player_ID', 'SEASON_ID']).cumcount() < 3\n",
    ").astype(int)\n",
    "\n",
    "# Average rest over last 5 games (game load)\n",
    "df['AVG_REST_LAST_5'] = (\n",
    "    df.groupby('Player_ID')['REST_DAYS']\n",
    "    .shift(1)\n",
    "    .rolling(5, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .fillna(7)\n",
    ")\n",
    "\n",
    "# Season timing\n",
    "df['SEASON_GAME_NUM'] = df.groupby(['Player_ID', 'SEASON_ID']).cumcount() + 1\n",
    "\n",
    "# FIX: Extract year correctly from SEASON_ID (format: \"22019\" -> \"2019\")\n",
    "df['SEASON_YEAR'] = df['SEASON_ID'].astype(str).str[1:5]\n",
    "df['DAYS_INTO_SEASON'] = (\n",
    "    df['GAME_DATE'] - pd.to_datetime(df['SEASON_YEAR'] + '-10-01')\n",
    ").dt.days\n",
    "\n",
    "# Normalized season progression (for quadratic term)\n",
    "days_min = df['DAYS_INTO_SEASON'].min()\n",
    "days_max = df['DAYS_INTO_SEASON'].max()\n",
    "df['DAYS_NORM'] = (df['DAYS_INTO_SEASON'] - days_min) / (days_max - days_min)\n",
    "df['DAYS_NORM_SQ'] = df['DAYS_NORM'] ** 2  # Captures inverted U-shape\n",
    "\n",
    "print(\"âœ… 10 game context features created\")\n",
    "print(f\"   REST_DAYS range: {df['REST_DAYS'].min():.0f} - {df['REST_DAYS'].max():.0f} days\")\n",
    "print(f\"   REST_DAYS_CAPPED: {df['REST_DAYS_CAPPED'].min():.0f} - {df['REST_DAYS_CAPPED'].max():.0f} days\")\n",
    "print(f\"   Season openers: {df['IS_SEASON_OPENER'].sum():,} games ({df['IS_SEASON_OPENER'].mean()*100:.1f}%)\")\n",
    "print(f\"   DAYS_INTO_SEASON: {df['DAYS_INTO_SEASON'].min()} to {df['DAYS_INTO_SEASON'].max()} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Player Role (5 features)\n",
    "\n",
    "**Why:** Bench players have 2.8x higher volatility (CV=1.25) than starters (CV=0.45).\n",
    "Model needs to know player role for appropriate uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating player role features...\n",
      "\n",
      "âœ… 5 player role features created\n",
      "   RECENT_MIN_AVG range: 0.0 - 44.2 min\n",
      "\n",
      "   Role distribution:\n",
      "      Bench     :  3,197 games (  3.5%)\n",
      "      Rotation  : 17,778 games ( 19.7%)\n",
      "      Starter   : 36,721 games ( 40.7%)\n",
      "      Star      : 32,578 games ( 36.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating player role features...\\n\")\n",
    "\n",
    "# Recent minutes average (leakage-safe)\n",
    "df['RECENT_MIN_AVG'] = (\n",
    "    df.groupby('Player_ID')['MIN']\n",
    "    .shift(1)  # CRITICAL: Don't use current game\n",
    "    .rolling(5, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Categorical role assignment\n",
    "df['MIN_ROLE'] = pd.cut(\n",
    "    df['RECENT_MIN_AVG'], \n",
    "    bins=[0, 10, 20, 30, 48], \n",
    "    labels=['Bench', 'Rotation', 'Starter', 'Star'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# One-hot encode\n",
    "role_dummies = pd.get_dummies(df['MIN_ROLE'], prefix='ROLE', dtype=int)\n",
    "df = pd.concat([df, role_dummies], axis=1)\n",
    "\n",
    "print(\"âœ… 5 player role features created\")\n",
    "print(f\"   RECENT_MIN_AVG range: {df['RECENT_MIN_AVG'].min():.1f} - {df['RECENT_MIN_AVG'].max():.1f} min\\n\")\n",
    "print(\"   Role distribution:\")\n",
    "for role in ['Bench', 'Rotation', 'Starter', 'Star']:\n",
    "    count = df[f'ROLE_{role}'].sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"      {role:10s}: {count:6,} games ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Season Progression (5 features)\n",
    "\n",
    "**Why:** Performance follows inverted U-shape:\n",
    "- October: 11.83 PTS (ramp-up)\n",
    "- February: 12.82 PTS (peak)\n",
    "- April: 12.70 PTS (fatigue/load management)\n",
    "\n",
    "Linear features can't capture this - need quadratic + categorical phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating season phase categories...\n",
      "\n",
      "âœ… 5 season progression features created\n",
      "   DAYS_INTO_SEASON: 17 - 318 days\n",
      "   DAYS_NORM range: 0.000 - 1.000\n",
      "   DAYS_NORM_SQ range: 0.000 - 1.000\n",
      "\n",
      "   Phase distribution:\n",
      "      Early: 38,919 games ( 43.1%)\n",
      "      Peak : 40,230 games ( 44.6%)\n",
      "      Late : 11,125 games ( 12.3%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating season phase categories...\\n\")\n",
    "\n",
    "# Categorical season phases\n",
    "# FIXED BINS: Based on actual DAYS_INTO_SEASON range (17-318 days)\n",
    "# Early: Oct/Nov/Dec (0-100 days)\n",
    "# Peak: Jan/Feb/Mar (100-180 days)\n",
    "# Late: Apr onwards (180-320 days, includes playoffs)\n",
    "df['SEASON_PHASE'] = pd.cut(\n",
    "    df['DAYS_INTO_SEASON'], \n",
    "    bins=[0, 100, 180, 320],\n",
    "    labels=['Early', 'Peak', 'Late'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# One-hot encode phases\n",
    "phase_dummies = pd.get_dummies(df['SEASON_PHASE'], prefix='PHASE', dtype=int)\n",
    "df = pd.concat([df, phase_dummies], axis=1)\n",
    "\n",
    "print(\"âœ… 5 season progression features created\")\n",
    "print(f\"   DAYS_INTO_SEASON: {df['DAYS_INTO_SEASON'].min()} - {df['DAYS_INTO_SEASON'].max()} days\")\n",
    "print(f\"   DAYS_NORM range: {df['DAYS_NORM'].min():.3f} - {df['DAYS_NORM'].max():.3f}\")\n",
    "print(f\"   DAYS_NORM_SQ range: {df['DAYS_NORM_SQ'].min():.3f} - {df['DAYS_NORM_SQ'].max():.3f}\\n\")\n",
    "print(\"   Phase distribution:\")\n",
    "for phase in ['Early', 'Peak', 'Late']:\n",
    "    count = df[f'PHASE_{phase}'].sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"      {phase:5s}: {count:6,} games ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trends (7 features)\n",
    "\n",
    "Performance momentum (slope) and volatility (std) over recent games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trend features...\n",
      "\n",
      "âœ… 7 trend features created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating trend features...\\n\")\n",
    "\n",
    "def calculate_trend(series):\n",
    "    \"\"\"Calculate linear trend (slope) of series\"\"\"\n",
    "    if len(series) < 2:\n",
    "        return 0\n",
    "    return np.polyfit(np.arange(len(series)), series, 1)[0]\n",
    "\n",
    "# Trend (slope) for key stats\n",
    "for stat in ['PTS', 'REB', 'AST', 'MIN']:\n",
    "    df[f'{stat}_TREND'] = (\n",
    "        df.groupby('Player_ID')[stat]\n",
    "        .shift(1)\n",
    "        .rolling(5, min_periods=2)\n",
    "        .apply(calculate_trend, raw=True)\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "# Volatility (std) for target variables\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    df[f'{stat}_VOLATILITY'] = (\n",
    "        df.groupby('Player_ID')[stat]\n",
    "        .shift(1)\n",
    "        .rolling(5, min_periods=2)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "print(\"âœ… 7 trend features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Season Stats (9 features)\n",
    "\n",
    "**FIXED HOT_HAND:** Old version selected elite players (Giannis, Jokic), not momentum.\n",
    "\n",
    "**New approach:** Continuous momentum score = (last_3_avg - last_10_avg) / last_10_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating season stats (with FIXED hot hand)...\n",
      "\n",
      "âœ… 9 season stats features created\n",
      "\n",
      "   Hot hand momentum scores:\n",
      "      PTS: avg_score=+0.003, hot_games=34.0%\n",
      "      REB: avg_score=+0.002, hot_games=35.6%\n",
      "      AST: avg_score=+0.004, hot_games=39.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating season stats (with FIXED hot hand)...\\n\")\n",
    "\n",
    "# Season averages (expanding mean)\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    df[f'{stat}_SEASON_AVG'] = (\n",
    "        df.groupby(['Player_ID', 'SEASON_ID'])[stat]\n",
    "        .apply(lambda x: x.shift(1).expanding().mean())\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "# HOT_HAND momentum scores\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    # Short-term performance (last 3 games)\n",
    "    short_term = (\n",
    "        df.groupby('Player_ID')[stat]\n",
    "        .shift(1)\n",
    "        .rolling(3, min_periods=2)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    # Long-term baseline (last 10 games)\n",
    "    long_term = (\n",
    "        df.groupby('Player_ID')[stat]\n",
    "        .shift(1)\n",
    "        .rolling(10, min_periods=5)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    # Continuous momentum score\n",
    "    df[f'{stat}_HOT_HAND_SCORE'] = (\n",
    "        (short_term - long_term) / (long_term + 1e-6)\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Binary version (hot if >10% above baseline)\n",
    "    df[f'{stat}_HOT_HAND_BINARY'] = (\n",
    "        df[f'{stat}_HOT_HAND_SCORE'] > 0.1\n",
    "    ).astype(int)\n",
    "\n",
    "print(\"âœ… 9 season stats features created\\n\")\n",
    "print(\"   Hot hand momentum scores:\")\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    score_col = f'{stat}_HOT_HAND_SCORE'\n",
    "    binary_col = f'{stat}_HOT_HAND_BINARY'\n",
    "    mean_score = df[score_col].mean()\n",
    "    hot_pct = df[binary_col].mean() * 100\n",
    "    print(f\"      {stat}: avg_score={mean_score:+.3f}, hot_games={hot_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Shot Location Features (20 features)\n",
    "\n",
    "**KEY FOR PTS IMPROVEMENT:** Shot distribution and efficiency by zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shot chart data...\n",
      "\n",
      "âœ… Loaded 885,698 shots\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading shot chart data...\\n\")\n",
    "\n",
    "df_shots = pd.read_parquet('../data/raw/shot_charts_all.parquet')\n",
    "\n",
    "# Map zones to simplified categories\n",
    "def map_zone(z):\n",
    "    if z == 'Restricted Area': return 'RESTRICTED_AREA'\n",
    "    if z == 'In The Paint (Non-RA)': return 'PAINT'\n",
    "    if z == 'Mid-Range': return 'MIDRANGE'\n",
    "    if z in ['Above the Break 3', 'Left Corner 3', 'Right Corner 3']: return 'THREE_PT'\n",
    "    return 'OTHER'\n",
    "\n",
    "df_shots['ZONE'] = df_shots['SHOT_ZONE_BASIC'].apply(map_zone)\n",
    "df_shots['GAME_DATE'] = pd.to_datetime(df_shots['GAME_DATE'], format='%Y%m%d')\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_shots):,} shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating shots by player-game-zone...\n",
      "\n",
      "âœ… Shot aggregation: 88,600 player-games\n"
     ]
    }
   ],
   "source": [
    "print(\"Aggregating shots by player-game-zone...\\n\")\n",
    "\n",
    "# Aggregate by player-game-zone\n",
    "shot_agg = df_shots.groupby(['Player_ID', 'GAME_ID', 'GAME_DATE', 'ZONE']).agg({\n",
    "    'SHOT_MADE_FLAG': 'sum',\n",
    "    'SHOT_ATTEMPTED_FLAG': 'sum'\n",
    "}).reset_index()\n",
    "shot_agg.columns = ['Player_ID', 'GAME_ID', 'GAME_DATE', 'ZONE', 'FGM', 'FGA']\n",
    "\n",
    "# Pivot to wide format\n",
    "fga_pivot = shot_agg.pivot_table(\n",
    "    index=['Player_ID', 'GAME_ID', 'GAME_DATE'], \n",
    "    columns='ZONE', \n",
    "    values='FGA', \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "fgm_pivot = shot_agg.pivot_table(\n",
    "    index=['Player_ID', 'GAME_ID', 'GAME_DATE'], \n",
    "    columns='ZONE', \n",
    "    values='FGM', \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns\n",
    "fga_pivot.columns = ['Player_ID', 'GAME_ID', 'GAME_DATE'] + [f'{c}_FGA' for c in fga_pivot.columns[3:]]\n",
    "fgm_pivot.columns = ['Player_ID', 'GAME_ID', 'GAME_DATE'] + [f'{c}_FGM' for c in fgm_pivot.columns[3:]]\n",
    "\n",
    "# Merge\n",
    "df_shot = fga_pivot.merge(\n",
    "    fgm_pivot[['Player_ID', 'GAME_ID'] + [c for c in fgm_pivot.columns if 'FGM' in c]], \n",
    "    on=['Player_ID', 'GAME_ID']\n",
    ")\n",
    "\n",
    "print(f\"âœ… Shot aggregation: {len(df_shot):,} player-games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating shot percentages and quality...\n",
      "\n",
      "âœ… Shot metrics calculated\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating shot percentages and quality...\\n\")\n",
    "\n",
    "# Total attempts\n",
    "df_shot['TOTAL_FGA'] = (\n",
    "    df_shot['RESTRICTED_AREA_FGA'] + \n",
    "    df_shot['PAINT_FGA'] + \n",
    "    df_shot['MIDRANGE_FGA'] + \n",
    "    df_shot['THREE_PT_FGA']\n",
    ")\n",
    "\n",
    "# Distribution (% of shots from each zone)\n",
    "for zone in ['RESTRICTED_AREA', 'PAINT', 'MIDRANGE', 'THREE_PT']:\n",
    "    df_shot[f'{zone}_FGA_PCT'] = (\n",
    "        df_shot[f'{zone}_FGA'] / df_shot['TOTAL_FGA'].replace(0, 1) * 100\n",
    "    )\n",
    "\n",
    "# Efficiency (FG% by zone)\n",
    "for zone in ['RESTRICTED_AREA', 'PAINT', 'MIDRANGE', 'THREE_PT']:\n",
    "    df_shot[f'{zone}_FG_PCT'] = (\n",
    "        df_shot[f'{zone}_FGM'] / df_shot[f'{zone}_FGA'].replace(0, 1) * 100\n",
    "    )\n",
    "\n",
    "# Average shot distance\n",
    "shot_dist = df_shots.groupby(['Player_ID', 'GAME_ID', 'GAME_DATE'])['SHOT_DISTANCE'].mean().reset_index()\n",
    "shot_dist.columns = ['Player_ID', 'GAME_ID', 'GAME_DATE', 'AVG_SHOT_DISTANCE']\n",
    "df_shot = df_shot.merge(shot_dist, on=['Player_ID', 'GAME_ID', 'GAME_DATE'], how='left')\n",
    "\n",
    "# Shot quality score (weighted by expected points)\n",
    "df_shot['SHOT_QUALITY_SCORE'] = (\n",
    "    df_shot['RESTRICTED_AREA_FGA_PCT'] * 1.3 +  # High-value shots\n",
    "    df_shot['PAINT_FGA_PCT'] * 1.0 +\n",
    "    df_shot['MIDRANGE_FGA_PCT'] * 0.8 +         # Low-value shots\n",
    "    df_shot['THREE_PT_FGA_PCT'] * 1.1            # High-value if made\n",
    ")\n",
    "\n",
    "print(\"âœ… Shot metrics calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rolling averages for shot features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shot rolling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 240.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 20 shot rolling features created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating rolling averages for shot features...\\n\")\n",
    "\n",
    "df_shot = df_shot.sort_values(['Player_ID', 'GAME_DATE'])\n",
    "\n",
    "shot_features = [\n",
    "    'RESTRICTED_AREA_FGA_PCT', 'PAINT_FGA_PCT', 'MIDRANGE_FGA_PCT', 'THREE_PT_FGA_PCT',\n",
    "    'RESTRICTED_AREA_FG_PCT', 'PAINT_FG_PCT', 'MIDRANGE_FG_PCT', 'THREE_PT_FG_PCT',\n",
    "    'AVG_SHOT_DISTANCE', 'SHOT_QUALITY_SCORE'\n",
    "]\n",
    "\n",
    "for feat in tqdm(shot_features, desc=\"Shot rolling\"):\n",
    "    for window in [5, 10]:\n",
    "        df_shot[f'{feat}_LAST_{window}'] = (\n",
    "            df_shot.groupby('Player_ID')[feat]\n",
    "            .shift(1)\n",
    "            .rolling(window, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "# Keep only rolling features for merge\n",
    "shot_cols = ['Player_ID', 'GAME_ID', 'GAME_DATE'] + [\n",
    "    c for c in df_shot.columns if 'LAST_' in c\n",
    "]\n",
    "df_shot_rolling = df_shot[shot_cols]\n",
    "\n",
    "print(f\"âœ… 20 shot rolling features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Merge All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging game logs with shot features...\n",
      "\n",
      "âœ… Merged dataset: 90,274 games, 113 columns\n",
      "   Missing shot data: 1.8%\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging game logs with shot features...\\n\")\n",
    "\n",
    "# Standardize column names for merge\n",
    "if 'GAME_ID' not in df.columns and 'Game_ID' in df.columns:\n",
    "    df['GAME_ID'] = df['Game_ID']\n",
    "\n",
    "# Merge\n",
    "df_complete = df.merge(\n",
    "    df_shot_rolling, \n",
    "    on=['Player_ID', 'GAME_ID', 'GAME_DATE'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Merged dataset: {len(df_complete):,} games, {df_complete.shape[1]} columns\")\n",
    "print(f\"   Missing shot data: {df_complete[[c for c in df_complete.columns if 'LAST_' in c]].isnull().mean().mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Data Quality Flags\n",
    "\n",
    "Flag games that may need filtering during training due to extreme conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data quality flags...\n",
      "\n",
      "âœ… Data quality flags created\n",
      "\n",
      "   Quality issues:\n",
      "      Extreme rest (>10 days):  2,742 games (3.0%)\n",
      "      Low minutes (<5 min):     2,033 games (2.3%)\n",
      "      Exclude from training:    4,571 games (5.1%)\n",
      "      Clean training data:      85,703 games (94.9%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding data quality flags...\\n\")\n",
    "\n",
    "# Flag 1: Extreme rest (>10 days) - likely injury returns\n",
    "df_complete['EXTREME_REST'] = (df_complete['REST_DAYS'] > 10).astype(int)\n",
    "\n",
    "# Flag 2: Very low minutes (<5 min) - DNP-CD, garbage time\n",
    "df_complete['LOW_MINUTES'] = (df_complete['MIN'] < 5).astype(int)\n",
    "\n",
    "# Combined training quality flag\n",
    "df_complete['INCLUDE_IN_TRAINING'] = (\n",
    "    (df_complete['EXTREME_REST'] == 0) & \n",
    "    (df_complete['LOW_MINUTES'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"âœ… Data quality flags created\\n\")\n",
    "print(f\"   Quality issues:\")\n",
    "print(f\"      Extreme rest (>10 days):  {df_complete['EXTREME_REST'].sum():,} games ({df_complete['EXTREME_REST'].mean()*100:.1f}%)\")\n",
    "print(f\"      Low minutes (<5 min):     {df_complete['LOW_MINUTES'].sum():,} games ({df_complete['LOW_MINUTES'].mean()*100:.1f}%)\")\n",
    "print(f\"      Exclude from training:    {(~df_complete['INCLUDE_IN_TRAINING'].astype(bool)).sum():,} games ({(~df_complete['INCLUDE_IN_TRAINING'].astype(bool)).mean()*100:.1f}%)\")\n",
    "print(f\"      Clean training data:      {df_complete['INCLUDE_IN_TRAINING'].sum():,} games ({df_complete['INCLUDE_IN_TRAINING'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Finalize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining final feature set (81 features)...\n",
      "\n",
      "âœ… Final dataset prepared\n",
      "\n",
      "   Total games: 85,630\n",
      "   Total features: 81\n",
      "\n",
      "   Feature breakdown:\n",
      "      Rolling averages:  27\n",
      "      Game context:      10\n",
      "      Player role:        5\n",
      "      Season phase:       3\n",
      "      Trends:             7\n",
      "      Season stats:       9\n",
      "      Shot location:     20\n",
      "      ----------------\n",
      "      TOTAL:             81 features\n",
      "\n",
      "   Data quality:\n",
      "      Clean for training: 82,477 (96.3%)\n",
      "      Requires filtering: 3,153 (3.7%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining final feature set (81 features)...\\n\")\n",
    "\n",
    "feature_columns = [\n",
    "    # ========== ROLLING AVERAGES (27 features) ==========\n",
    "    'PTS_last_3', 'PTS_last_5', 'PTS_last_10',\n",
    "    'REB_last_3', 'REB_last_5', 'REB_last_10',\n",
    "    'AST_last_3', 'AST_last_5', 'AST_last_10',\n",
    "    'MIN_last_3', 'MIN_last_5', 'MIN_last_10',\n",
    "    'FGA_last_3', 'FGA_last_5', 'FGA_last_10',\n",
    "    'FTA_last_3', 'FTA_last_5', 'FTA_last_10',\n",
    "    'TOV_last_3', 'TOV_last_5', 'TOV_last_10',\n",
    "    'FG_PCT_last_5', 'FG_PCT_last_10',\n",
    "    'FG3_PCT_last_5', 'FG3_PCT_last_10',\n",
    "    'FT_PCT_last_5', 'FT_PCT_last_10',\n",
    "    \n",
    "    # ========== GAME CONTEXT (10 features) ==========\n",
    "    'IS_HOME', \n",
    "    'REST_DAYS', 'REST_DAYS_CAPPED',\n",
    "    'BACK_TO_BACK', 'IS_SEASON_OPENER', 'AVG_REST_LAST_5',\n",
    "    'SEASON_GAME_NUM', 'DAYS_INTO_SEASON',\n",
    "    'DAYS_NORM', 'DAYS_NORM_SQ',\n",
    "    \n",
    "    # ========== PLAYER ROLE (5 features) ==========\n",
    "    'RECENT_MIN_AVG',\n",
    "    'ROLE_Bench', 'ROLE_Rotation', 'ROLE_Starter', 'ROLE_Star',\n",
    "    \n",
    "    # ========== SEASON PHASE (3 features) ==========\n",
    "    'PHASE_Early', 'PHASE_Peak', 'PHASE_Late',\n",
    "    \n",
    "    # ========== TRENDS (7 features) ==========\n",
    "    'PTS_TREND', 'REB_TREND', 'AST_TREND', 'MIN_TREND',\n",
    "    'PTS_VOLATILITY', 'REB_VOLATILITY', 'AST_VOLATILITY',\n",
    "    \n",
    "    # ========== SEASON STATS (9 features) ==========\n",
    "    'PTS_SEASON_AVG', 'REB_SEASON_AVG', 'AST_SEASON_AVG',\n",
    "    'PTS_HOT_HAND_SCORE', 'REB_HOT_HAND_SCORE', 'AST_HOT_HAND_SCORE',\n",
    "    'PTS_HOT_HAND_BINARY', 'REB_HOT_HAND_BINARY', 'AST_HOT_HAND_BINARY',\n",
    "    \n",
    "    # ========== SHOT LOCATION (20 features) ==========\n",
    "    'RESTRICTED_AREA_FGA_PCT_LAST_5', 'RESTRICTED_AREA_FGA_PCT_LAST_10',\n",
    "    'PAINT_FGA_PCT_LAST_5', 'PAINT_FGA_PCT_LAST_10',\n",
    "    'MIDRANGE_FGA_PCT_LAST_5', 'MIDRANGE_FGA_PCT_LAST_10',\n",
    "    'THREE_PT_FGA_PCT_LAST_5', 'THREE_PT_FGA_PCT_LAST_10',\n",
    "    'RESTRICTED_AREA_FG_PCT_LAST_5', 'RESTRICTED_AREA_FG_PCT_LAST_10',\n",
    "    'PAINT_FG_PCT_LAST_5', 'PAINT_FG_PCT_LAST_10',\n",
    "    'MIDRANGE_FG_PCT_LAST_5', 'MIDRANGE_FG_PCT_LAST_10',\n",
    "    'THREE_PT_FG_PCT_LAST_5', 'THREE_PT_FG_PCT_LAST_10',\n",
    "    'AVG_SHOT_DISTANCE_LAST_5', 'AVG_SHOT_DISTANCE_LAST_10',\n",
    "    'SHOT_QUALITY_SCORE_LAST_5', 'SHOT_QUALITY_SCORE_LAST_10'\n",
    "]\n",
    "\n",
    "# Metadata columns\n",
    "tracking = ['Player_ID', 'PLAYER_NAME', 'GAME_ID', 'GAME_DATE', 'SEASON_ID']\n",
    "\n",
    "# Quality flags - categorical metadata for analysis (not features)\n",
    "# NOTE: IS_SEASON_OPENER removed - it's already a feature!\n",
    "quality_flags = ['INCLUDE_IN_TRAINING', 'EXTREME_REST', 'LOW_MINUTES', \n",
    "                 'MIN_ROLE', 'SEASON_PHASE']\n",
    "\n",
    "targets = ['PTS', 'REB', 'AST']\n",
    "\n",
    "# Create final dataset\n",
    "df_final = df_complete[tracking + feature_columns + quality_flags + targets].copy()\n",
    "\n",
    "# Fill missing shot data with 0 (players with no shot chart data)\n",
    "shot_cols = [c for c in feature_columns if any(x in c for x in \n",
    "            ['RESTRICTED', 'PAINT', 'MIDRANGE', 'THREE_PT', 'SHOT_QUALITY', 'AVG_SHOT_DISTANCE'])]\n",
    "df_final[shot_cols] = df_final[shot_cols].fillna(0)\n",
    "\n",
    "# Drop first 3 games per player-season (insufficient rolling history)\n",
    "df_final = df_final[df_final['SEASON_GAME_NUM'] >= 4].copy()\n",
    "\n",
    "print(f\"âœ… Final dataset prepared\\n\")\n",
    "print(f\"   Total games: {len(df_final):,}\")\n",
    "print(f\"   Total features: {len(feature_columns)}\\n\")\n",
    "print(f\"   Feature breakdown:\")\n",
    "print(f\"      Rolling averages:  27\")\n",
    "print(f\"      Game context:      10\")\n",
    "print(f\"      Player role:        5\")\n",
    "print(f\"      Season phase:       3\")\n",
    "print(f\"      Trends:             7\")\n",
    "print(f\"      Season stats:       9\")\n",
    "print(f\"      Shot location:     20\")\n",
    "print(f\"      ----------------\")\n",
    "print(f\"      TOTAL:             81 features\\n\")\n",
    "print(f\"   Data quality:\")\n",
    "print(f\"      Clean for training: {df_final['INCLUDE_IN_TRAINING'].sum():,} ({df_final['INCLUDE_IN_TRAINING'].mean()*100:.1f}%)\")\n",
    "print(f\"      Requires filtering: {(~df_final['INCLUDE_IN_TRAINING'].astype(bool)).sum():,} ({(~df_final['INCLUDE_IN_TRAINING'].astype(bool)).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final dataset and metadata...\n",
      "\n",
      "======================================================================\n",
      "âœ… FEATURE ENGINEERING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Files saved:\n",
      "  ðŸ“Š data/processed/features_complete.parquet\n",
      "  ðŸ“‹ data/processed/feature_metadata.json\n",
      "\n",
      "Dataset summary:\n",
      "  Total games:    85,630\n",
      "  Total players:  369\n",
      "  Total features: 81\n",
      "  Date range:     2019-10-28 to 2024-04-14\n",
      "\n",
      "Quality improvements from v1.0:\n",
      "  âœ… REST_DAYS capped at 7 days\n",
      "  âœ… Player role features added (5)\n",
      "  âœ… Season progression non-linearity (quadratic + phases)\n",
      "  âœ… HOT_HAND fixed (binary â†’ continuous momentum)\n",
      "  âœ… Data quality flags for training/evaluation\n",
      "\n",
      "Next step: Notebooks 04-05 for model training!\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving final dataset and metadata...\\n\")\n",
    "\n",
    "proc_path = Path('../data/processed')\n",
    "proc_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save feature dataset\n",
    "df_final.to_parquet(proc_path / 'features_complete.parquet', index=False)\n",
    "\n",
    "# Save comprehensive metadata\n",
    "metadata = {\n",
    "    'version': '2.0',\n",
    "    'date_created': pd.Timestamp.now().isoformat(),\n",
    "    'total_features': len(feature_columns),\n",
    "    'total_games': len(df_final),\n",
    "    'total_players': df_final['Player_ID'].nunique(),\n",
    "    'date_range': {\n",
    "        'start': df_final['GAME_DATE'].min().isoformat(),\n",
    "        'end': df_final['GAME_DATE'].max().isoformat()\n",
    "    },\n",
    "    \n",
    "    'feature_names': feature_columns,\n",
    "    'feature_breakdown': {\n",
    "        'rolling_averages': 27,\n",
    "        'game_context': 10,\n",
    "        'player_role': 5,\n",
    "        'season_phase': 3,\n",
    "        'trends': 7,\n",
    "        'season_stats': 9,\n",
    "        'shot_location': 20\n",
    "    },\n",
    "    \n",
    "    'data_quality_improvements': {\n",
    "        'rest_days_capped': 'Capped at 7 days to remove injury return contamination',\n",
    "        'season_opener_flag': 'Flag first 3 games per player-season (cold-start handling)',\n",
    "        'player_role_features': 'Added RECENT_MIN_AVG and role categories (Bench/Rotation/Starter/Star)',\n",
    "        'season_progression': 'Added quadratic term and phase categories for non-linear time effects',\n",
    "        'hot_hand_fixed': 'Changed from binary elite-player selector to continuous momentum score',\n",
    "        'quality_flags': 'Added INCLUDE_IN_TRAINING, EXTREME_REST, LOW_MINUTES flags'\n",
    "    },\n",
    "    \n",
    "    'tracking_columns': tracking,\n",
    "    'target_columns': targets,\n",
    "    'quality_flags': quality_flags,\n",
    "    \n",
    "    'data_quality': {\n",
    "        'clean_training_games': int(df_final['INCLUDE_IN_TRAINING'].sum()),\n",
    "        'extreme_rest_games': int(df_final['EXTREME_REST'].sum()),\n",
    "        'low_minute_games': int(df_final['LOW_MINUTES'].sum()),\n",
    "        'season_opener_games': int(df_final['IS_SEASON_OPENER'].sum())\n",
    "    },\n",
    "    \n",
    "    'leakage_prevention': 'All features use .shift(1) before rolling/expanding operations',\n",
    "    \n",
    "    'usage_notes': {\n",
    "        'training_filter': 'Use INCLUDE_IN_TRAINING flag to filter outlier games during training',\n",
    "        'role_analysis': 'Use MIN_ROLE for stratified evaluation (bench vs starters have different volatility)',\n",
    "        'feature_selection': 'All 81 features are interpretable and validated by EDA'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(proc_path / 'feature_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"âœ… FEATURE ENGINEERING COMPLETE!\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  ðŸ“Š data/processed/features_complete.parquet\")\n",
    "print(f\"  ðŸ“‹ data/processed/feature_metadata.json\\n\")\n",
    "print(f\"Dataset summary:\")\n",
    "print(f\"  Total games:    {len(df_final):,}\")\n",
    "print(f\"  Total players:  {df_final['Player_ID'].nunique()}\")\n",
    "print(f\"  Total features: {len(feature_columns)}\")\n",
    "print(f\"  Date range:     {df_final['GAME_DATE'].min().date()} to {df_final['GAME_DATE'].max().date()}\\n\")\n",
    "print(f\"Quality improvements from v1.0:\")\n",
    "print(f\"  âœ… REST_DAYS capped at 7 days\")\n",
    "print(f\"  âœ… Player role features added (5)\")\n",
    "print(f\"  âœ… Season progression non-linearity (quadratic + phases)\")\n",
    "print(f\"  âœ… HOT_HAND fixed (binary â†’ continuous momentum)\")\n",
    "print(f\"  âœ… Data quality flags for training/evaluation\\n\")\n",
    "print(f\"Next step: Notebooks 04-05 for model training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
