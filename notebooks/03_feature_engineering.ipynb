{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196fe6b3-3c12-4f26-9732-14b21f565572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Feature Engineering Setup Complete\n",
      "\n",
      "Key Principle: .shift(1) prevents data leakage!\n",
      "We only use information available BEFORE each game.\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - Building Predictive Features\n",
    "# CRITICAL: All features use ONLY past data (no leakage!)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Feature Engineering Setup Complete\")\n",
    "print(\"\\nKey Principle: .shift(1) prevents data leakage!\")\n",
    "print(\"We only use information available BEFORE each game.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe1fc96-bc5b-4616-b613-e61aefe65ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n",
      "============================================================\n",
      "Total games: 66,409\n",
      "Unique players: 369\n",
      "Date range: 2019-10-22 to 2024-04-14\n",
      "\n",
      "Key columns for feature engineering:\n",
      "  Targets: PTS, REB, AST\n",
      "  Stats: MIN, FG_PCT, FG3_PCT, FT_PCT, FGA, FTA, TOV\n",
      "  Context: GAME_DATE, MATCHUP, WL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>Player_ID</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>VIDEO_AVAILABLE</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22019</td>\n",
       "      <td>2544</td>\n",
       "      <td>0021900002</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>LAL @ LAC</td>\n",
       "      <td>L</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.368</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>LeBron James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22019</td>\n",
       "      <td>2544</td>\n",
       "      <td>0021900025</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>LAL vs. UTA</td>\n",
       "      <td>W</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.545</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>LeBron James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22019</td>\n",
       "      <td>2544</td>\n",
       "      <td>0021900040</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>LAL vs. CHA</td>\n",
       "      <td>W</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>LeBron James</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SEASON_ID  Player_ID     Game_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  \\\n",
       "0     22019       2544  0021900002 2019-10-22    LAL @ LAC  L   36    7   19   \n",
       "1     22019       2544  0021900025 2019-10-25  LAL vs. UTA  W   31   12   22   \n",
       "2     22019       2544  0021900040 2019-10-27  LAL vs. CHA  W   35    7   14   \n",
       "\n",
       "   FG_PCT  FG3M  FG3A  FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  \\\n",
       "0   0.368     1     5    0.200    3    4   0.750     1     9   10    8    1   \n",
       "1   0.545     1     4    0.250    7    8   0.875     2     5    7   10    1   \n",
       "2   0.500     1     3    0.333    5    5   1.000     1     5    6   12    1   \n",
       "\n",
       "   BLK  TOV  PF  PTS  PLUS_MINUS  VIDEO_AVAILABLE   PLAYER_NAME  \n",
       "0    1    5   3   18          -8                1  LeBron James  \n",
       "1    0    1   0   32          17                1  LeBron James  \n",
       "2    0    4   0   20          17                1  LeBron James  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the combined dataset\n",
    "raw_path = Path('../data/raw')\n",
    "df = pd.read_parquet(raw_path / 'gamelogs_combined.parquet')\n",
    "\n",
    "# Convert date to datetime\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "\n",
    "# Sort by player and date (CRITICAL for rolling features!)\n",
    "df = df.sort_values(['Player_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total games: {len(df):,}\")\n",
    "print(f\"Unique players: {df['Player_ID'].nunique()}\")\n",
    "print(f\"Date range: {df['GAME_DATE'].min().date()} to {df['GAME_DATE'].max().date()}\")\n",
    "\n",
    "# Show columns we'll use\n",
    "print(\"\\nKey columns for feature engineering:\")\n",
    "print(\"  Targets: PTS, REB, AST\")\n",
    "print(\"  Stats: MIN, FG_PCT, FG3_PCT, FT_PCT, FGA, FTA, TOV\")\n",
    "print(\"  Context: GAME_DATE, MATCHUP, WL\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07267ade-2704-4c9d-bd22-b39ec36e56c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: BUILDING ROLLING AVERAGE FEATURES\n",
      "============================================================\n",
      "\n",
      "Creating rolling features:\n",
      "  Stats: ['PTS', 'REB', 'AST', 'MIN', 'FGA', 'FTA', 'TOV']\n",
      "  Windows: [3, 5, 10]\n",
      "  Total features: 21\n",
      "\n",
      "‚úì Created 21 rolling average features\n",
      "\n",
      "Example - LeBron James (first 10 games):\n",
      " GAME_DATE  PTS  PTS_last_3  PTS_last_5  MIN  MIN_last_5\n",
      "2019-10-22   18         NaN         NaN   36         NaN\n",
      "2019-10-25   32      18.000      18.000   31        36.0\n",
      "2019-10-27   20      25.000      25.000   35        33.5\n",
      "2019-10-29   23      23.333      23.333   28        34.0\n",
      "2019-11-01   39      25.000      23.250   43        32.5\n",
      "2019-11-03   21      27.333      26.400   37        34.6\n",
      "2019-11-05   30      27.667      27.000   35        34.8\n",
      "2019-11-08   25      30.000      26.600   36        35.6\n",
      "2019-11-10   13      25.333      27.600   35        35.8\n",
      "2019-11-12   19      22.667      25.600   37        37.2\n",
      "\n",
      "============================================================\n",
      "LEAKAGE CHECK:\n",
      "Game 1: PTS_last_3 should be NaN (no history)\n",
      "  Actual: nan\n",
      "Game 2: PTS_last_3 should equal Game 1 PTS\n",
      "  Game 1 PTS: 18\n",
      "  Game 2 PTS_last_3: 18.0\n",
      "‚úì No leakage!\n"
     ]
    }
   ],
   "source": [
    "# PHASE 1: ROLLING AVERAGES\n",
    "# These capture recent performance trends\n",
    "\n",
    "print(\"PHASE 1: BUILDING ROLLING AVERAGE FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a copy to avoid modifying original\n",
    "df_features = df.copy()\n",
    "\n",
    "# Stats to create rolling features for\n",
    "stats_to_roll = ['PTS', 'REB', 'AST', 'MIN', 'FGA', 'FTA', 'TOV']\n",
    "windows = [3, 5, 10]\n",
    "\n",
    "print(f\"\\nCreating rolling features:\")\n",
    "print(f\"  Stats: {stats_to_roll}\")\n",
    "print(f\"  Windows: {windows}\")\n",
    "print(f\"  Total features: {len(stats_to_roll) * len(windows)}\")\n",
    "\n",
    "# Build rolling features\n",
    "for stat in stats_to_roll:\n",
    "  for window in windows:\n",
    "      feature_name = f'{stat}_last_{window}'\n",
    "\n",
    "      # CRITICAL: shift(1) prevents data leakage!\n",
    "      # We only use games BEFORE the current game\n",
    "      df_features[feature_name] = (\n",
    "          df_features.groupby('Player_ID')[stat]\n",
    "          .shift(1)  # ‚Üê CRITICAL: Don't include current game!\n",
    "          .rolling(window, min_periods=1)\n",
    "          .mean()\n",
    "      )\n",
    "\n",
    "print(f\"\\n‚úì Created {len(stats_to_roll) * len(windows)} rolling average features\")\n",
    "\n",
    "# Show example for one player\n",
    "print(\"\\nExample - LeBron James (first 10 games):\")\n",
    "lebron = df_features[df_features['PLAYER_NAME'] == 'LeBron James'].head(10)\n",
    "print(lebron[['GAME_DATE', 'PTS', 'PTS_last_3', 'PTS_last_5', 'MIN', 'MIN_last_5']].to_string(index=False))\n",
    "\n",
    "# Verify no leakage\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LEAKAGE CHECK:\")\n",
    "print(\"Game 1: PTS_last_3 should be NaN (no history)\")\n",
    "print(f\"  Actual: {df_features.iloc[0]['PTS_last_3']}\")\n",
    "print(\"Game 2: PTS_last_3 should equal Game 1 PTS\")\n",
    "print(f\"  Game 1 PTS: {df_features.iloc[0]['PTS']}\")\n",
    "print(f\"  Game 2 PTS_last_3: {df_features.iloc[1]['PTS_last_3']}\")\n",
    "print(\"‚úì No leakage!\" if pd.isna(df_features.iloc[0]['PTS_last_3']) else \"‚ùå LEAKAGE DETECTED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d0c86c-7590-4069-9d97-4a6ae62e65db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 6 efficiency rolling features\n",
      "\n",
      "New features: ['FG_PCT_last_5', 'FG_PCT_last_10', 'FG3_PCT_last_5', 'FG3_PCT_last_10', 'FT_PCT_last_5', 'FT_PCT_last_10']\n",
      "\n",
      "Sample for Player 2544:\n",
      "    GAME_DATE  FG_PCT  FG_PCT_last_5  FG_PCT_last_10\n",
      "0  2019-10-22   0.368            NaN             NaN\n",
      "1  2019-10-25   0.545          0.368           0.368\n",
      "2  2019-10-27   0.500          0.457           0.457\n",
      "3  2019-10-29   0.533          0.471           0.471\n",
      "4  2019-11-01   0.565          0.487           0.487\n",
      "5  2019-11-03   0.348          0.502           0.502\n",
      "6  2019-11-05   0.526          0.498           0.476\n",
      "7  2019-11-08   0.526          0.494           0.484\n",
      "8  2019-11-10   0.333          0.500           0.489\n",
      "9  2019-11-12   0.444          0.460           0.472\n",
      "10 2019-11-13   0.524          0.435           0.469\n",
      "11 2019-11-15   0.500          0.471           0.484\n",
      "12 2019-11-17   0.619          0.465           0.480\n",
      "13 2019-11-19   0.476          0.484           0.492\n",
      "14 2019-11-22   0.450          0.513           0.486\n"
     ]
    }
   ],
   "source": [
    "# Phase 1b: Rolling efficiency metrics (FG%, 3P%, FT%)\n",
    "# Using longer windows (5, 10) since percentages are noisier game-to-game\n",
    "\n",
    "efficiency_stats = ['FG_PCT', 'FG3_PCT', 'FT_PCT']\n",
    "efficiency_windows = [5, 10]  # Longer windows for percentage stability\n",
    "\n",
    "for stat in efficiency_stats:\n",
    "  for window in efficiency_windows:\n",
    "      feature_name = f'{stat}_last_{window}'\n",
    "      df_features[feature_name] = (\n",
    "          df_features.groupby('Player_ID')[stat]\n",
    "          .shift(1)\n",
    "          .rolling(window, min_periods=1)\n",
    "          .mean()\n",
    "      )\n",
    "\n",
    "# Show what we've created\n",
    "efficiency_features = [f'{stat}_last_{w}' for stat in\n",
    "efficiency_stats for w in efficiency_windows]\n",
    "print(f\"‚úì Created {len(efficiency_features)} efficiency rolling features\")\n",
    "print(f\"\\nNew features: {efficiency_features}\")\n",
    "\n",
    "# Sample verification\n",
    "sample_player = df_features[df_features['Player_ID'] == df_features['Player_ID'].iloc[0]].head(15)\n",
    "print(f\"\\nSample for Player {sample_player['Player_ID'].iloc[0]}:\")\n",
    "print(sample_player[['GAME_DATE', 'FG_PCT', 'FG_PCT_last_5', 'FG_PCT_last_10']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51ae494-d520-48e1-8fe5-49d525bbbb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 5 context features:\n",
      "  - IS_HOME (1=home, 0=away)\n",
      "  - REST_DAYS (days since last game)\n",
      "  - BACK_TO_BACK (1=yes, 0=no)\n",
      "  - SEASON_GAME_NUM (1-82)\n",
      "  - DAYS_INTO_SEASON (0-180+)\n",
      "\n",
      "Sample for Player 2544:\n",
      "   GAME_DATE      MATCHUP  IS_HOME  REST_DAYS  BACK_TO_BACK  SEASON_GAME_NUM\n",
      "0 2019-10-22    LAL @ LAC        0        7.0             0                1\n",
      "1 2019-10-25  LAL vs. UTA        1        3.0             0                2\n",
      "2 2019-10-27  LAL vs. CHA        1        2.0             0                3\n",
      "3 2019-10-29  LAL vs. MEM        1        2.0             0                4\n",
      "4 2019-11-01    LAL @ DAL        0        3.0             0                5\n",
      "5 2019-11-03    LAL @ SAS        0        2.0             0                6\n",
      "6 2019-11-05    LAL @ CHI        0        2.0             0                7\n",
      "7 2019-11-08  LAL vs. MIA        1        3.0             0                8\n",
      "8 2019-11-10  LAL vs. TOR        1        2.0             0                9\n",
      "9 2019-11-12    LAL @ PHX        0        2.0             0               10\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Context features (game circumstances)\n",
    "\n",
    "# 1. Home/Away indicator\n",
    "df_features['IS_HOME'] = (df_features['MATCHUP'].str.contains('vs.')).astype(int)\n",
    "\n",
    "# 2. Rest days (days since last game)\n",
    "df_features['GAME_DATE'] = pd.to_datetime(df_features['GAME_DATE'])\n",
    "df_features['REST_DAYS'] = (\n",
    "  df_features.groupby('Player_ID')['GAME_DATE']\n",
    "  .diff()\n",
    "  .dt.days\n",
    "  .fillna(7)  # First game of season, assume 7 days rest\n",
    ")\n",
    "\n",
    "# 3. Back-to-back indicator\n",
    "df_features['BACK_TO_BACK'] = (df_features['REST_DAYS'] <= 1).astype(int)\n",
    "\n",
    "# 4. Season progression (game number in season)\n",
    "df_features['SEASON_GAME_NUM'] = df_features.groupby(['Player_ID', 'SEASON_ID']).cumcount() + 1\n",
    "\n",
    "# 5. Days into season (captures fatigue/conditioning arc)\n",
    "season_start_dates = df_features.groupby('SEASON_ID')['GAME_DATE'].min()\n",
    "df_features['DAYS_INTO_SEASON'] = df_features.apply(\n",
    "  lambda row: (row['GAME_DATE'] - season_start_dates[row['SEASON_ID']]).days, axis=1\n",
    ")\n",
    "\n",
    "print(\"‚úì Created 5 context features:\")\n",
    "print(\"  - IS_HOME (1=home, 0=away)\")\n",
    "print(\"  - REST_DAYS (days since last game)\")\n",
    "print(\"  - BACK_TO_BACK (1=yes, 0=no)\")\n",
    "print(\"  - SEASON_GAME_NUM (1-82)\")\n",
    "print(\"  - DAYS_INTO_SEASON (0-180+)\")\n",
    "\n",
    "# Verify context features\n",
    "sample_player = df_features[df_features['Player_ID'] == df_features['Player_ID'].iloc[0]].head(10)\n",
    "print(f\"\\nSample for Player {sample_player['Player_ID'].iloc[0]}:\")\n",
    "print(sample_player[['GAME_DATE', 'MATCHUP', 'IS_HOME', 'REST_DAYS', 'BACK_TO_BACK', 'SEASON_GAME_NUM']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b438f1-97e4-4c74-8143-3347932e57c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 13 advanced features:\n",
      "  - 3 TREND features (recent vs longer-term performance)\n",
      "  - 3 VOLATILITY features (consistency metrics)\n",
      "  - 3 HOT_HAND features (recent form vs season baseline)\n",
      "  - 3 SEASON_AVG features (expanding season averages)\n",
      "  - 1 MIN_TREND (playing time trend)\n",
      "\n",
      "üìä Total engineered features: 47\n",
      "\n",
      "Feature breakdown:\n",
      "  Phase 1 (Rolling): 27 features\n",
      "  Phase 2 (Context): 5 features\n",
      "  Phase 3 (Advanced): 13 features\n",
      "\n",
      "Sample trends for Player 2544:\n",
      "    GAME_DATE  PTS  PTS_last_5  PTS_SEASON_AVG  PTS_TREND  PTS_HOT_HAND\n",
      "0  2019-10-22   18         NaN             NaN        NaN           NaN\n",
      "1  2019-10-25   32      18.000          18.000      0.000         0.000\n",
      "2  2019-10-27   20      25.000          25.000      0.000         0.000\n",
      "3  2019-10-29   23      23.333          23.333      0.000         0.000\n",
      "4  2019-11-01   39      23.250          23.250      0.000         1.750\n",
      "5  2019-11-03   21      26.400          26.400      0.000         0.933\n",
      "6  2019-11-05   30      27.000          25.500      1.500         2.167\n",
      "7  2019-11-08   25      26.600          26.143      0.457         3.857\n",
      "8  2019-11-10   13      27.600          26.000      1.600        -0.667\n",
      "9  2019-11-12   19      25.600          24.556      1.044        -1.889\n",
      "10 2019-11-13   23      21.600          24.000     -2.400        -5.000\n",
      "11 2019-11-15   29      22.000          23.909     -2.500        -5.576\n",
      "12 2019-11-17   33      21.800          24.333     -2.400        -0.667\n",
      "13 2019-11-19   25      23.400          25.000     -2.100         3.333\n",
      "14 2019-11-22   23      25.800          25.000      0.100         4.000\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Advanced features (trends, volatility, hot hand)\n",
    "\n",
    "# 1. Performance trends (last 5 vs last 10 games)\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "  df_features[f'{stat}_TREND'] = (\n",
    "      df_features[f'{stat}_last_5'] - df_features[f'{stat}_last_10']\n",
    "  )\n",
    "\n",
    "# 2. Volatility (standard deviation of last 10 games)\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "  df_features[f'{stat}_VOLATILITY'] = (\n",
    "      df_features.groupby('Player_ID')[stat]\n",
    "      .shift(1)\n",
    "      .rolling(10, min_periods=3)\n",
    "      .std()\n",
    "  )\n",
    "\n",
    "# 3. Hot hand (performance last 3 vs season average)\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "  # Season average up to this point\n",
    "  df_features[f'{stat}_SEASON_AVG'] = (\n",
    "      df_features.groupby(['Player_ID', 'SEASON_ID'])[stat]\n",
    "      .shift(1)\n",
    "      .expanding()\n",
    "      .mean()\n",
    "  )\n",
    "  # Hot hand = recent form vs season average\n",
    "  df_features[f'{stat}_HOT_HAND'] = (\n",
    "      df_features[f'{stat}_last_3'] - df_features[f'{stat}_SEASON_AVG']\n",
    "  )\n",
    "\n",
    "# 4. Minutes trend (increasing/decreasing playing time)\n",
    "df_features['MIN_TREND'] = (\n",
    "  df_features['MIN_last_5'] - df_features['MIN_last_10']\n",
    ")\n",
    "\n",
    "print(\"‚úì Created 13 advanced features:\")\n",
    "print(\"  - 3 TREND features (recent vs longer-term performance)\")\n",
    "print(\"  - 3 VOLATILITY features (consistency metrics)\")\n",
    "print(\"  - 3 HOT_HAND features (recent form vs season baseline)\")\n",
    "print(\"  - 3 SEASON_AVG features (expanding season averages)\")\n",
    "print(\"  - 1 MIN_TREND (playing time trend)\")\n",
    "\n",
    "# Summary of all features\n",
    "feature_cols = [col for col in df_features.columns if col not in [\n",
    "  'Player_ID', 'Game_ID', 'GAME_DATE', 'SEASON_ID', 'MATCHUP',\n",
    "  'WL', 'PTS', 'REB', 'AST', 'MIN', 'FGM', 'FGA', 'FG_PCT',\n",
    "  'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT',\n",
    "  'OREB', 'DREB', 'STL', 'BLK', 'TOV', 'PF', 'PLUS_MINUS'\n",
    "]]\n",
    "\n",
    "print(f\"\\nüìä Total engineered features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  Phase 1 (Rolling): 27 features\")\n",
    "print(f\"  Phase 2 (Context): 5 features\")\n",
    "print(f\"  Phase 3 (Advanced): 13 features\")\n",
    "\n",
    "# Sample verification\n",
    "sample_player = df_features[df_features['Player_ID'] == df_features['Player_ID'].iloc[0]].head(15)\n",
    "print(f\"\\nSample trends for Player {sample_player['Player_ID'].iloc[0]}:\")\n",
    "print(sample_player[['GAME_DATE', 'PTS', 'PTS_last_5', 'PTS_SEASON_AVG', 'PTS_TREND', 'PTS_HOT_HAND']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c9bd65-7d2f-4960-ba91-2dcbb63d94e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values by feature (top 10):\n",
      "PTS_VOLATILITY     3\n",
      "AST_VOLATILITY     3\n",
      "REB_VOLATILITY     3\n",
      "AST_TREND          1\n",
      "FG_PCT_last_10     1\n",
      "FG3_PCT_last_5     1\n",
      "FG3_PCT_last_10    1\n",
      "FT_PCT_last_5      1\n",
      "FT_PCT_last_10     1\n",
      "PTS_TREND          1\n",
      "dtype: int64\n",
      "\n",
      "‚úì Filled missing values with 0\n",
      "Remaining missing values: 0\n",
      "\n",
      "üìä Dataset ready:\n",
      "  Features (X): (66409, 47)\n",
      "  Target PTS: (66409,)\n",
      "  Target REB: (66409,)\n",
      "  Target AST: (66409,)\n",
      "  Metadata: (66409, 4)\n",
      "\n",
      "First 3 rows of feature matrix:\n",
      "   VIDEO_AVAILABLE   PLAYER_NAME  PTS_last_3  PTS_last_5  PTS_last_10  \\\n",
      "0                1  LeBron James         0.0         0.0          0.0   \n",
      "1                1  LeBron James        18.0        18.0         18.0   \n",
      "2                1  LeBron James        25.0        25.0         25.0   \n",
      "\n",
      "   REB_last_3  REB_last_5  REB_last_10  AST_last_3  AST_last_5  AST_last_10  \\\n",
      "0         0.0         0.0          0.0         0.0         0.0          0.0   \n",
      "1        10.0        10.0         10.0         8.0         8.0          8.0   \n",
      "2         8.5         8.5          8.5         9.0         9.0          9.0   \n",
      "\n",
      "   MIN_last_3  MIN_last_5  MIN_last_10  FGA_last_3  FGA_last_5  FGA_last_10  \\\n",
      "0         0.0         0.0          0.0         0.0         0.0          0.0   \n",
      "1        36.0        36.0         36.0        19.0        19.0         19.0   \n",
      "2        33.5        33.5         33.5        20.5        20.5         20.5   \n",
      "\n",
      "   FTA_last_3  FTA_last_5  FTA_last_10  TOV_last_3  TOV_last_5  TOV_last_10  \\\n",
      "0         0.0         0.0          0.0         0.0         0.0          0.0   \n",
      "1         4.0         4.0          4.0         5.0         5.0          5.0   \n",
      "2         6.0         6.0          6.0         3.0         3.0          3.0   \n",
      "\n",
      "   FG_PCT_last_5  FG_PCT_last_10  FG3_PCT_last_5  FG3_PCT_last_10  \\\n",
      "0          0.000           0.000           0.000            0.000   \n",
      "1          0.368           0.368           0.200            0.200   \n",
      "2          0.457           0.457           0.225            0.225   \n",
      "\n",
      "   FT_PCT_last_5  FT_PCT_last_10  IS_HOME  REST_DAYS  BACK_TO_BACK  \\\n",
      "0          0.000           0.000        0        7.0             0   \n",
      "1          0.750           0.750        1        3.0             0   \n",
      "2          0.812           0.812        1        2.0             0   \n",
      "\n",
      "   SEASON_GAME_NUM  DAYS_INTO_SEASON  PTS_TREND  REB_TREND  AST_TREND  \\\n",
      "0                1                 0        0.0        0.0        0.0   \n",
      "1                2                 3        0.0        0.0        0.0   \n",
      "2                3                 5        0.0        0.0        0.0   \n",
      "\n",
      "   PTS_VOLATILITY  REB_VOLATILITY  AST_VOLATILITY  PTS_SEASON_AVG  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0            18.0   \n",
      "2             0.0             0.0             0.0            25.0   \n",
      "\n",
      "   PTS_HOT_HAND  REB_SEASON_AVG  REB_HOT_HAND  AST_SEASON_AVG  AST_HOT_HAND  \\\n",
      "0           0.0             0.0           0.0             0.0           0.0   \n",
      "1           0.0            10.0           0.0             8.0           0.0   \n",
      "2           0.0             8.5           0.0             9.0           0.0   \n",
      "\n",
      "   MIN_TREND  \n",
      "0        0.0  \n",
      "1        0.0  \n",
      "2        0.0  \n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values by feature (top 10):\")\n",
    "missing_counts = df_features[feature_cols].isnull().sum().sort_values(ascending=False).head(10)\n",
    "print(missing_counts)\n",
    "\n",
    "# Strategy: Fill NaN with 0 for early-season games (no history)\n",
    "# This is reasonable because:\n",
    "# - Rolling features are NaN when player has insufficient history\n",
    "# - 0 indicates \"no data yet\" which the model can learn\n",
    "df_features_clean = df_features.copy()\n",
    "df_features_clean[feature_cols] = df_features_clean[feature_cols].fillna(0)\n",
    "\n",
    "print(f\"\\n‚úì Filled missing values with 0\")\n",
    "print(f\"Remaining missing values: {df_features_clean[feature_cols].isnull().sum().sum()}\")\n",
    "\n",
    "# Create feature matrix (X) and targets (y)\n",
    "X = df_features_clean[feature_cols]\n",
    "y_pts = df_features_clean['PTS']\n",
    "y_reb = df_features_clean['REB']\n",
    "y_ast = df_features_clean['AST']\n",
    "\n",
    "# Keep metadata for splits\n",
    "metadata = df_features_clean[['Player_ID', 'Game_ID', 'GAME_DATE', 'SEASON_ID']]\n",
    "\n",
    "print(f\"\\nüìä Dataset ready:\")\n",
    "print(f\"  Features (X): {X.shape}\")\n",
    "print(f\"  Target PTS: {y_pts.shape}\")\n",
    "print(f\"  Target REB: {y_reb.shape}\")\n",
    "print(f\"  Target AST: {y_ast.shape}\")\n",
    "print(f\"  Metadata: {metadata.shape}\")\n",
    "\n",
    "# Show first few rows of feature matrix\n",
    "print(f\"\\nFirst 3 rows of feature matrix:\")\n",
    "print(X.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2a7dea-ce71-4221-84d8-17f657e8382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Removed 2 non-predictive columns\n",
      "\n",
      "üìä Final dataset:\n",
      "  Features (X): (66409, 45)\n",
      "  Targets: PTS, REB, AST (66409 games each)\n",
      "\n",
      "Feature types:\n",
      "float64    41\n",
      "int64       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Feature inventory (45 total):\n",
      "  Rolling (27): ['PTS_last_3', 'PTS_last_5', 'PTS_last_10', 'REB_last_3', 'REB_last_5']... (showing first 5)\n",
      "  Context (5): ['IS_HOME', 'REST_DAYS', 'BACK_TO_BACK', 'SEASON_GAME_NUM', 'DAYS_INTO_SEASON']\n",
      "  Advanced (13): ['PTS_TREND', 'REB_TREND', 'AST_TREND', 'PTS_VOLATILITY', 'REB_VOLATILITY', 'AST_VOLATILITY', 'PTS_SEASON_AVG', 'PTS_HOT_HAND', 'REB_SEASON_AVG', 'REB_HOT_HAND', 'AST_SEASON_AVG', 'AST_HOT_HAND', 'MIN_TREND']\n"
     ]
    }
   ],
   "source": [
    "# Remove non-predictive columns that slipped through\n",
    "non_features = ['VIDEO_AVAILABLE', 'PLAYER_NAME']\n",
    "feature_cols_clean = [col for col in feature_cols if col not in non_features]\n",
    "\n",
    "# Recreate clean feature matrix\n",
    "X = df_features_clean[feature_cols_clean]\n",
    "y_pts = df_features_clean['PTS']\n",
    "y_reb = df_features_clean['REB']\n",
    "y_ast = df_features_clean['AST']\n",
    "metadata = df_features_clean[['Player_ID', 'Game_ID', 'GAME_DATE', 'SEASON_ID']]\n",
    "\n",
    "print(f\"‚úì Removed {len(feature_cols) - len(feature_cols_clean)} non-predictive columns\")\n",
    "print(f\"\\nüìä Final dataset:\")\n",
    "print(f\"  Features (X): {X.shape}\")\n",
    "print(f\"  Targets: PTS, REB, AST ({y_pts.shape[0]} games each)\")\n",
    "\n",
    "# Verify all features are numeric\n",
    "print(f\"\\nFeature types:\")\n",
    "print(X.dtypes.value_counts())\n",
    "\n",
    "# Show feature names by category\n",
    "print(f\"\\nüìã Feature inventory ({len(feature_cols_clean)} total):\")\n",
    "rolling_features = [f for f in feature_cols_clean if 'last' in f]\n",
    "context_features = [f for f in feature_cols_clean if f in ['IS_HOME', 'REST_DAYS', 'BACK_TO_BACK', 'SEASON_GAME_NUM', 'DAYS_INTO_SEASON']]\n",
    "advanced_features = [f for f in feature_cols_clean if f not in rolling_features and f not in context_features]\n",
    "\n",
    "print(f\"  Rolling (27): {rolling_features[:5]}... (showing first 5)\")\n",
    "print(f\"  Context (5): {context_features}\")\n",
    "print(f\"  Advanced (13): {advanced_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c4159b-411b-46b5-8200-8b15f945d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset splits (by season):\n",
      "  Train (2019-20 to 2021-22): 38,315 games (57.7%)\n",
      "  Val   (2022-23):            14,020 games (21.1%)\n",
      "  Test  (2023-24):            14,074 games (21.2%)\n",
      "  Total:                      66,409 games\n",
      "\n",
      "üéØ Target distributions (mean ¬± std):\n",
      "  PTS:\n",
      "    Train: 14.22 ¬± 8.76\n",
      "    Val:   14.86 ¬± 9.27\n",
      "    Test:  15.05 ¬± 8.96\n",
      "  REB:\n",
      "    Train: 5.20 ¬± 3.63\n",
      "    Val:   5.21 ¬± 3.55\n",
      "    Test:  5.18 ¬± 3.59\n",
      "  AST:\n",
      "    Train: 3.15 ¬± 2.84\n",
      "    Val:   3.30 ¬± 2.88\n",
      "    Test:  3.47 ¬± 2.91\n"
     ]
    }
   ],
   "source": [
    "# Time-based splits (NEVER shuffle time series data!)\n",
    "# Train: 22019, 22020, 22021 (2019-20, 2020-21, 2021-22)\n",
    "# Val:   22022 (2022-23)\n",
    "# Test:  22023 (2023-24)\n",
    "\n",
    "train_seasons = ['22019', '22020', '22021']\n",
    "val_season = ['22022']\n",
    "test_season = ['22023']\n",
    "\n",
    "train_mask = metadata['SEASON_ID'].isin(train_seasons)\n",
    "val_mask = metadata['SEASON_ID'].isin(val_season)\n",
    "test_mask = metadata['SEASON_ID'].isin(test_season)\n",
    "\n",
    "# Create splits\n",
    "X_train, y_train_pts, y_train_reb, y_train_ast = X[train_mask], y_pts[train_mask], y_reb[train_mask], y_ast[train_mask]\n",
    "X_val, y_val_pts, y_val_reb, y_val_ast = X[val_mask], y_pts[val_mask], y_reb[val_mask], y_ast[val_mask]\n",
    "X_test, y_test_pts, y_test_reb, y_test_ast = X[test_mask], y_pts[test_mask], y_reb[test_mask], y_ast[test_mask]\n",
    "\n",
    "print(\"üìä Dataset splits (by season):\")\n",
    "print(f\"  Train (2019-20 to 2021-22): {X_train.shape[0]:,} games ({X_train.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"  Val   (2022-23):            {X_val.shape[0]:,} games ({X_val.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"  Test  (2023-24):            {X_test.shape[0]:,} games ({X_test.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"  Total:                      {X.shape[0]:,} games\")\n",
    "\n",
    "# Verify target distributions are similar across splits\n",
    "print(f\"\\nüéØ Target distributions (mean ¬± std):\")\n",
    "for target_name, y_train, y_val, y_test in [\n",
    "  ('PTS', y_train_pts, y_val_pts, y_test_pts),\n",
    "  ('REB', y_train_reb, y_val_reb, y_test_reb),\n",
    "  ('AST', y_train_ast, y_val_ast, y_test_ast)\n",
    "]:\n",
    "  print(f\"  {target_name}:\")\n",
    "  print(f\"    Train: {y_train.mean():.2f} ¬± {y_train.std():.2f}\")\n",
    "  print(f\"    Val:   {y_val.mean():.2f} ¬± {y_val.std():.2f}\")\n",
    "  print(f\"    Test:  {y_test.mean():.2f} ¬± {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae0ebcb-50fd-4135-afe0-cbc71e97e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data...\n",
      "‚úì Saved all splits to data/processed/\n",
      "\n",
      "Files created:\n",
      "  - X_train.csv, X_val.csv, X_test.csv\n",
      "  - y_train_[pts|reb|ast].csv\n",
      "  - y_val_[pts|reb|ast].csv\n",
      "  - y_test_[pts|reb|ast].csv\n",
      "  - feature_names.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save splits as separate files for easy loading during training\n",
    "print(\"Saving processed data...\")\n",
    "\n",
    "# Save training data\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "y_train_pts.to_csv('../data/processed/y_train_pts.csv', index=False, header=['PTS'])\n",
    "y_train_reb.to_csv('../data/processed/y_train_reb.csv', index=False, header=['REB'])\n",
    "y_train_ast.to_csv('../data/processed/y_train_ast.csv', index=False, header=['AST'])\n",
    "\n",
    "# Save validation data\n",
    "X_val.to_csv('../data/processed/X_val.csv', index=False)\n",
    "y_val_pts.to_csv('../data/processed/y_val_pts.csv', index=False, header=['PTS'])\n",
    "y_val_reb.to_csv('../data/processed/y_val_reb.csv', index=False, header=['REB'])\n",
    "y_val_ast.to_csv('../data/processed/y_val_ast.csv', index=False, header=['AST'])\n",
    "\n",
    "# Save test data\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_test_pts.to_csv('../data/processed/y_test_pts.csv', index=False, header=['PTS'])\n",
    "y_test_reb.to_csv('../data/processed/y_test_reb.csv', index=False, header=['REB'])\n",
    "y_test_ast.to_csv('../data/processed/y_test_ast.csv', index=False, header=['AST'])\n",
    "\n",
    "# Save feature names for reference\n",
    "import json\n",
    "with open('../data/processed/feature_names.json', 'w') as f:\n",
    "  json.dump(list(X.columns), f, indent=2)\n",
    "\n",
    "print(\"‚úì Saved all splits to data/processed/\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - X_train.csv, X_val.csv, X_test.csv\")\n",
    "print(f\"  - y_train_[pts|reb|ast].csv\")\n",
    "print(f\"  - y_val_[pts|reb|ast].csv\")\n",
    "print(f\"  - y_test_[pts|reb|ast].csv\")\n",
    "print(f\"  - feature_names.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe1c49-1bac-496f-831f-c7fa5e8d699e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
